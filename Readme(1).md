# üìÑ Document Question Answering (RAG) App
A **Retrieval-Augmented Generation (RAG)** application that allows users to upload documents and ask questions. The system retrieves relevant content from the uploaded files and generates **accurate answers strictly grounded in the document context**.

üöÄ **Live Demo (Hugging Face Space):**
üëâ [HuggingFace App](https://huggingface.co/spaces/Sowmya135/RetrievalAugmentedGenerator)

## üöÄ Features
* üìÅ Upload multiple documents (`PDF`, `TXT`, `DOCX`)
* üîç Semantic search using **FAISS vector database**
* üß† Context-aware answers using **FLAN-T5**
* ‚ùå Prevents hallucinations (answers only from documents)
* üåê Clean web UI built with **Gradio**
* üîê No paid APIs or token billing

## üõ†Ô∏è Tech Stack
* **Python**
* **Gradio** ‚Äì User Interface
* **LangChain** ‚Äì RAG pipeline
* **Hugging Face Transformers**
* **Sentence Transformers** ‚Äì Text Embeddings
* **FAISS** ‚Äì Vector Similarity Search

## üß† How It Works (RAG Flow)
1. User uploads one or more documents
2. Documents are loaded and split into overlapping chunks
3. Each chunk is converted into vector embeddings
4. Embeddings are stored in a FAISS vector database
5. User asks a question
6. Relevant chunks are retrieved via semantic similarity
7. The LLM generates an answer **only from the retrieved context**

## üìÇ Supported File Types
* `.pdf`
* `.txt`
* `.docx`

## ‚öôÔ∏è Model Details

### üîπ Embedding Model

* `sentence-transformers/all-MiniLM-L6-v2`

### üîπ Language Model

* `google/flan-t5-base`

> This is an **open-source LLM** running locally inside Hugging Face Spaces.

## üí∞ Cost Clarification (Important)

‚úÖ **No token-based billing**
‚úÖ **No API keys required**
‚úÖ **No OpenAI / paid APIs used**

The model runs **locally on Hugging Face Spaces**, so users can freely interact with the app without incurring costs.

## üì• Clone the Repository from HuggingFace Spaces

```bash
git clone https://huggingface.co/spaces/Sowmya135/RetrievalAugmentedGenerator
cd RetrievalAugmentedGenerator
```

## üì• Clone the Repository from Github

```bash
git clone https://github.com/Sowmya135/RAG
cd RAG
```

## ‚ñ∂Ô∏è Run Locally (Step-by-Step)

### 1Ô∏è‚É£ Create a Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 2Ô∏è‚É£ Install Dependencies

```bash
pip install gradio langchain langchain-community langchain-huggingface \
transformers sentence-transformers faiss-cpu pypdf docx2txt
```

### 3Ô∏è‚É£ Run the Application

```bash
python app.py
```

Open your browser and go to:

```
http://127.0.0.1:7860
```

## ‚ö†Ô∏è NOTE
* Vector store is built once per session
* Restart the Space to upload new documents
* Large documents may take longer to process
* Runs on CPU by default (GPU improves speed if enabled)

## üì∏ Example Use Cases
* Academic document Q&A
* Research paper exploration
* Resume or report analysis
* Study material querying

## ‚≠ê Final Note

This project demonstrates **real-world RAG architecture** using only **open-source tools**, making it ideal for learning, showcasing, and deployment without cost concerns.
